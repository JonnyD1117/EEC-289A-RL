# Sutton & Barto Chapter 3: Finite Markov Decision Process (MDP)


## Goals, Rewards, Returns, & Episodes 

## Policies & Value Functions

## Optimal Policies and Optimal Value Functions 

## Optimality and Approximations 